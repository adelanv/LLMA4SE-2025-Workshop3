{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "908494f7-6a00-43a8-b17d-8061a45f349d",
   "metadata": {},
   "source": [
    "# Workshop: Multi-Agent LLMs and Knowledge Graphs for Monitoring and Sustaining Software Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f0815",
   "metadata": {},
   "source": [
    "## Create Environment and Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c595db8a",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]\n",
      "C:\\Users\\simeont\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n",
      "$(python --version)\n",
      "Requirement already satisfied: neo4j in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.28.2)\n",
      "Requirement already satisfied: pytz in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from neo4j) (2025.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\simeont\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen-agentchat in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.7.4)\n",
      "Requirement already satisfied: autogen-ext[openai] in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.7.4)\n",
      "Requirement already satisfied: autogen-core==0.7.4 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogen-agentchat) (0.7.4)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogen-core==0.7.4->autogen-agentchat) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.34.1 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogen-core==0.7.4->autogen-agentchat) (1.36.0)\n",
      "Requirement already satisfied: pillow>=11.0.0 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogen-core==0.7.4->autogen-agentchat) (11.3.0)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogen-core==0.7.4->autogen-agentchat) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogen-core==0.7.4->autogen-agentchat) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\simeont\\appdata\\roaming\\python\\python311\\site-packages (from autogen-core==0.7.4->autogen-agentchat) (4.12.2)\n",
      "Requirement already satisfied: aiofiles in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogen-ext[openai]) (24.1.0)\n",
      "Requirement already satisfied: openai>=1.93 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogen-ext[openai]) (1.100.2)\n",
      "Requirement already satisfied: tiktoken>=0.8.0 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogen-ext[openai]) (0.11.0)\n",
      "Requirement already satisfied: ollama>=0.4.7 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogen-ext[openai]) (0.5.3)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ollama>=0.4.7->autogen-ext[openai]) (0.28.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.93->autogen-ext[openai]) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.93->autogen-ext[openai]) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.93->autogen-ext[openai]) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.93->autogen-ext[openai]) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.93->autogen-ext[openai]) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.93->autogen-ext[openai]) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27->ollama>=0.4.7->autogen-ext[openai]) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27->ollama>=0.4.7->autogen-ext[openai]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama>=0.4.7->autogen-ext[openai]) (0.16.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-api>=1.34.1->autogen-core==0.7.4->autogen-agentchat) (8.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.7.4->autogen-agentchat) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.7.4->autogen-agentchat) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.7.4->autogen-agentchat) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (2.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\simeont\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai>=1.93->autogen-ext[openai]) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core==0.7.4->autogen-agentchat) (3.21.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\simeont\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\simeont\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\simeont\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\simeont\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\simeont\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\simeont\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydriller in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.8)\n",
      "Requirement already satisfied: gitpython in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydriller) (3.1.45)\n",
      "Requirement already satisfied: pytz in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydriller) (2025.2)\n",
      "Requirement already satisfied: types-pytz in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydriller) (2025.2.0.20250809)\n",
      "Requirement already satisfied: lizard==1.17.10 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydriller) (1.17.10)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython->pydriller) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\simeont\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->pydriller) (5.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\simeont\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install python=3.10.18\n",
    "\n",
    "import sys \n",
    "print(sys.version)\n",
    "print(sys.executable)\n",
    "!echo $(python --version)\n",
    "!pip3 install neo4j\n",
    "!pip3 install -U \"autogen-agentchat\" \"autogen-ext[openai]\" \"autogen-ext[ollama]\"\n",
    "!pip3 install matplotlib\n",
    "!pip3 install networkx\n",
    "!pip3 install pydriller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181f4883",
   "metadata": {},
   "source": [
    "## Docker Installation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e72721",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# in bash: \n",
    "# docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6996e2e-c01c-4bc4-85e4-2ed67e135854",
   "metadata": {},
   "source": [
    "## Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa1fd082",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from neo4j import GraphDatabase\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece1e9d",
   "metadata": {},
   "source": [
    "##  Prepare the model (API key and configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd98e5",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser(allow_no_value = True)\n",
    "config.read('openaiapi.ini')\n",
    "openai_api_key = config.get('openai', 'OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff4e11-079c-4817-9bf7-642769b0e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=openai_api_key,\n",
    "    max_tokens = None,\n",
    "    temperature = None,\n",
    "    seed = None,\n",
    "    top_p = None,\n",
    "    parallel_tool_calls=False  # Disable for Swarms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb610756",
   "metadata": {},
   "source": [
    "## Setup Neo4J Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\"neo4j://localhost:7687\", auth=(\"neo4j\", \"password\"))\n",
    "\n",
    "# First check for connectivity:\n",
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def query_neo4j(query: str) -> str:\n",
    "    \"\"\"Run a Cypher query against Neo4j and return results. Returns String representation.\"\"\"\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            records = [record.data() for record in result]\n",
    "        return repr(records)  \n",
    "    except Exception as e:\n",
    "        return repr({\"error\": str(e)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Second check for connectivity (run actual query):\n",
    "await query_neo4j(\"RETURN 'Checking connectivity with Neo4j!' AS msg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17d604",
   "metadata": {},
   "source": [
    "## Agent Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now()\n",
    "current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506938f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_agent = AssistantAgent(\n",
    "    name=\"graph_operator\",\n",
    "    model_client=openai_model_client,\n",
    "    tools=[query_neo4j],\n",
    "    system_message =\"\"\"Your name is graph_operator. You generate **Cypher queries** and execute them.\n",
    "                    You have access to a tool called query_neo4j that you can use to run Cypher queries and optionally retrieve results. \n",
    "                    Use the schema below: \\\n",
    "                    Node Types:\n",
    "                   (1) CodeChange \n",
    "                    - Properties: \n",
    "                        uid: str\n",
    "                        timestamp: date\n",
    "                        change_description: str\n",
    "                        change_location: List[str]   # files, functions, or classes affected\n",
    "                   (2) SourceCode \n",
    "                      - Properties:\n",
    "                        uid: str\n",
    "                        code_description: str\n",
    "                        lines_of_code: int\n",
    "                   (3) CommitMessage\n",
    "                     - Properties:\n",
    "                        uid: str\n",
    "                        message_text: str\n",
    "                        author: str\n",
    "                        commit_hash: str\n",
    "                    Relationship Types:\n",
    "                 (1) (n:CodeChange)-[:]->(m:CodeChange)         # Temporal sequence of changes\n",
    "                 (2) (n:SourceCode)-[:]->(m:CodeChange)         # Source code elements impacted by the change\n",
    "                 (3) (n:CommitMessage)-[:]->(m:CodeChange)      # Commit that introduced the change\n",
    "                    Rules:\n",
    "                - Only use this schema. Do not invent nodes or relationships.\n",
    "                - Only one Cypher statement per query is allowed.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ee985",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = f\"\"\"\n",
    "Date: {current_date}.\n",
    "Commit: a13f9c7 by Alice Smith\n",
    "Commit Message: \"Refactored statistics module to improve clarity and reduce duplication\"\n",
    "\n",
    "Changes:\n",
    "- Refactoring performed on functions `calculate_sum` and `summarize_report` in `statistics.py`\n",
    "- Moved helper function `format_output` from `utils/helpers.py` into `statistics.py` for better cohesion\n",
    "- Reduced lines of code in `summarize_report` from 120 to 80\n",
    "\n",
    "Context:\n",
    "- This refactor was done as a follow-up to commit `98df231` (previous bugfix in statistics module).\n",
    "- Refactor categorized as 'code cleanup' and 'modularity improvement'.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e859f063",
   "metadata": {},
   "source": [
    "## Start chat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41460136",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def assistant_run_stream() -> None:\n",
    "    # Option 1: read each message from the stream (as shown in the previous example).\n",
    "    # async for message in agent.run_stream(task=\"Find information on AutoGen\"):\n",
    "    #     print(message)\n",
    "\n",
    "    # Option 2: use Console to print all messages as they appear.\n",
    "    await Console(\n",
    "        graph_agent.run_stream(task=task),\n",
    "        output_stats=True,  # Enable stats printing.\n",
    "    )\n",
    "\n",
    "\n",
    "# Use asyncio.run(assistant_run_stream()) when running in a script.\n",
    "await assistant_run_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40acc860",
   "metadata": {},
   "source": [
    "## Visualize Graph Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_query(query):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        G = nx.DiGraph()\n",
    "        for record in result:\n",
    "            start = record[\"a\"]\n",
    "            end = record[\"b\"]\n",
    "            rel = record[\"r\"].type\n",
    "            G.add_edge(start[\"uid\"], end[\"uid\"], label=rel)\n",
    "\n",
    "    if len(G.nodes) == 0:\n",
    "        print(\"No results returned. Check your query or database contents.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", node_size=2000, font_size=10, arrows=True)\n",
    "    edge_labels = nx.get_edge_attributes(G, 'label')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd06869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_query(\"MATCH (a)-[r]->(b) RETURN a, r, b LIMIT 20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead9568",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f7d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class StructuredOutput(BaseModel):\n",
    "    technical_debt_type: str\n",
    "    description: str\n",
    "    location: str\n",
    "\n",
    "class StructuredSuggestOutput(BaseModel):\n",
    "    suggested_fix: str \n",
    "\n",
    "class StructuredRefactorOutput(BaseModel):\n",
    "    description_of_fix: str\n",
    "    refactored_code: str \n",
    "\n",
    "class StructuredTestOutput(BaseModel):\n",
    "    evaluation: str\n",
    "    accepted: str\n",
    "\n",
    "model_client = OllamaChatCompletionClient(model=\"qwen3:0.6b\")\n",
    "ollama_model_client = OllamaChatCompletionClient(\n",
    "    model=\"qwen3:0.6b\",\n",
    "    response_format=StructuredOutput,\n",
    "    max_tokens = None,\n",
    "    temperature = None,\n",
    "    seed = None,\n",
    "    top_p = None,\n",
    "    parallel_tool_calls=False  # Disable for Swarms\n",
    "\n",
    ")\n",
    "\n",
    "ollama_model_client_suggest = OllamaChatCompletionClient(\n",
    "    model=\"qwen3:0.6b\",\n",
    "    response_format=StructuredSuggestOutput,\n",
    "    max_tokens = None,\n",
    "    temperature = None,\n",
    "    seed = None,\n",
    "    top_p = None,\n",
    "    parallel_tool_calls=False  # Disable for Swarms\n",
    ")\n",
    "\n",
    "ollama_model_client_refactor = OllamaChatCompletionClient(\n",
    "    model=\"qwen3:0.6b\",\n",
    "    response_format=StructuredRefactorOutput,\n",
    "    max_tokens = None,\n",
    "    temperature = None,\n",
    "    seed = None,\n",
    "    top_p = None,\n",
    "    parallel_tool_calls=False  # Disable for Swarms\n",
    "    \n",
    ")\n",
    "\n",
    "ollama_model_client_test = OllamaChatCompletionClient(\n",
    "    model=\"qwen3:0.6b\",\n",
    "    response_format=StructuredTestOutput,\n",
    "    max_tokens = None,\n",
    "    temperature = None,\n",
    "    seed = None,\n",
    "    top_p = None,\n",
    "    parallel_tool_calls=False  # Disable for Swarms\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc0ff31",
   "metadata": {},
   "source": [
    "Creating Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39f4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Agents\n",
    "\n",
    "debt_agent = AssistantAgent(\n",
    "    name=\"Technical_debt_identifier\",\n",
    "    model_client=ollama_model_client,\n",
    "    system_message=\"Identify technical and architectural debt in provided code.\",\n",
    ")\n",
    "\n",
    "suggestion_agent = AssistantAgent(\n",
    "    name=\"Technical_debt_refactoring_suggestor\",\n",
    "    model_client=ollama_model_client_suggest,\n",
    "    system_message=\"Suggest refactoring strategies for given technical debt items.\",\n",
    ")\n",
    "\n",
    "refactoring_agent = AssistantAgent(\n",
    "    name=\"Technical_debt_refactoring_agent\",\n",
    "    model_client=ollama_model_client_refactor,\n",
    "    system_message=\"Refactor given code based on provided suggestions.\",\n",
    ")\n",
    "\n",
    "test_agent = AssistantAgent(\n",
    "    name=\"Test_agent\",\n",
    "    model_client=ollama_model_client_test,\n",
    "    system_message=\"Evaluate the given code. Provide feedback on whether the refactoring was successful or if further changes are needed.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code for validating JSON structure in output from \n",
    "\n",
    "def validate_json_structure(data: dict) -> None:\n",
    "    \"\"\"\n",
    "    Validate the structure of the JSON data.\n",
    "    \n",
    "    Args:\n",
    "        data (dict): The JSON data to validate\n",
    "        \n",
    "    Raises:\n",
    "        JSONValidationError: If the JSON structure is invalid\n",
    "    \"\"\"\n",
    "    if not isinstance(data, dict):\n",
    "        raise Exception(\"Root element must be a dictionary\")\n",
    "        \n",
    "    for commit_hash, entries in data.items():\n",
    "        if not isinstance(entries, list):\n",
    "            raise Exception(f\"Entries for commit {commit_hash} must be a list\")\n",
    "            \n",
    "        for entry in entries:\n",
    "            if not isinstance(entry, dict):\n",
    "                raise Exception(f\"Each entry in commit {commit_hash} must be a dictionary\")\n",
    "\n",
    "            if 'technicalDebts' in entry and not isinstance(entry['technicalDebts'], list):\n",
    "                raise Exception(f\"technicalDebts in commit {commit_hash} must be a list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8bbed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydriller import Repository\n",
    "def analyze_commits(repo_url, begin_commit, end_commit, debts, debts_file):\n",
    "    \"\"\"\n",
    "    The function will iterate through the commits and fetch the changed content from the previous commit.\n",
    "\n",
    "    \"\"\"\n",
    "    commit_count = 0\n",
    "    for commit in Repository(repo_url, from_commit=begin_commit, to_commit=end_commit).traverse_commits():\n",
    "        print(\"Analyzing commit: %s\", commit.hash)\n",
    "        print(\"In the repo: %s\", repo_url)\n",
    "        commit_count += 1\n",
    "\n",
    "        analyze_modifications(commit, debts, debts_file, repo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f64008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_modifications(commit, debts, debts_file, repo_url):\n",
    "    \"\"\"\n",
    "    The function will go thorugh each commit in the repo and analyze.\n",
    "\n",
    "    \"\"\"\n",
    "    for modification in commit.modified_files:\n",
    "        if not modification.source_code or not is_source_code(modification.new_path):\n",
    "            continue\n",
    "\n",
    "        print(\"Analyzing file: %s\", modification.new_path)\n",
    "        enumerated_content = enumerate_file(modification.source_code)\n",
    "\n",
    "        #Pass to starting point of agent interaction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248cbac5",
   "metadata": {},
   "source": [
    "Load Testcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e3de033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def calculate_total(items):\n",
      "    total = 0\n",
      "    for item in items:\n",
      "        total += item['price'] * item['quantity']\n",
      "    return total\n",
      "\n",
      "# TODO: Add error handling for missing keys\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "code_folder = \"codebase\"\n",
    "os.makedirs(code_folder, exist_ok=True)\n",
    "\n",
    "sample_file_path = os.path.join(code_folder, \"example.py\")\n",
    "with open(sample_file_path, \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "def calculate_total(items):\n",
    "    total = 0\n",
    "    for item in items:\n",
    "        total += item['price'] * item['quantity']\n",
    "    return total\n",
    "\n",
    "# TODO: Add error handling for missing keys\n",
    "\"\"\")\n",
    "\n",
    "with open(sample_file_path, \"r\") as f:\n",
    "    code_content = f.read()\n",
    "\n",
    "print(code_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a452c",
   "metadata": {},
   "source": [
    "Manually go through each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import UserProxyAgent\n",
    "\n",
    "user_proxy = UserProxyAgent(name=\"User\")\n",
    "\n",
    "debt_response = user_proxy.initiate_chat(\n",
    "    recipient=agent1,\n",
    "    message=f\"Analyze the following code and identify technical debt:\\n\\n{code_content}\"\n",
    ")\n",
    "print(debt_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await ollama_model_client.create([UserMessage(content=f\"Analyze the following code and identify technical debt:\\n\\n{code_content}\", source=\"user\")])\n",
    "print(response)\n",
    "technical_debt_item = response\n",
    "await ollama_model_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await ollama_model_client_suggest.create([UserMessage(content=f\"Suggest refactoring for this code,:\\n\\n{code_content} to fix this technical debt \\n\\n{technical_debt_item}. Describe how a user should perform the refactoring.\", source=\"user\")])\n",
    "print(response)\n",
    "suggested_fix = response\n",
    "await ollama_model_client_suggest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0270b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await ollama_model_client_refactor.create([UserMessage(content=f\"Refactor this code,:\\n\\n{code_content} to fix this technical debt item \\n\\n{technical_debt_item} following this suggestion  \\n\\n{suggested_fix}. Provide both the description and the full code.\", source=\"user\")])\n",
    "print(response)\n",
    "refactored_code = response\n",
    "await ollama_model_client_refactor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74a4ca",
   "metadata": {},
   "source": [
    "Now with agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20260076",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await debt_agent.run(task=f\"Analyze the following code and identify technical debt:\\n\\n{code_content}\")\n",
    "print(result)\n",
    "identified_debt = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await suggestion_agent.run(task=f\"Suggest refactoring for this code,:\\n\\n{code_content} to fix this technical debt \\n\\n{identified_debt}. Describe how a user should perform the refactoring.\")\n",
    "print(result)\n",
    "fix = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95988fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await refactoring_agent.run(task=f\"Refactor this code,:\\n\\n{code_content} to fix this technical debt item \\n\\n{technical_debt_item} following this suggestion  \\n\\n{fix}. Provide both the description and the full code.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f732d4a",
   "metadata": {},
   "source": [
    "Now we can create a selector group chat, to allow for more complex interactions between agents.\n",
    "\n",
    "Here, a selector agent will be created to allow for the code to be analysed until it has passed a test. The selector will make a choice depending on the output of th test agent, and will either pass the refactored code further or make the refactoring agent attempt another refactoring with further information from the test agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c8c2e-4f19-4750-99a4-8452865fc736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Analyze the following code and identify technical debt:\n",
      "\n",
      "\n",
      "def calculate_total(items):\n",
      "    total = 0\n",
      "    for item in items:\n",
      "        total += item['price'] * item['quantity']\n",
      "    return total\n",
      "\n",
      "# TODO: Add error handling for missing keys\n",
      ". Then suggest a refactoring strategy and refactor the code.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.messages import BaseAgentEvent, BaseChatMessage\n",
    "from typing import List, Sequence\n",
    "#from autogen_agentchat import GroupChatManager\n",
    "\n",
    "\n",
    "text_mention_termination = TextMentionTermination(\"TERMINATE\")\n",
    "max_messages_termination = MaxMessageTermination(max_messages=25)\n",
    "termination = text_mention_termination | max_messages_termination\n",
    "\n",
    "model_client = OllamaChatCompletionClient(model=\"qwen3:0.6b\")\n",
    "\n",
    "\n",
    "selector_prompt = \"\"\"You are coordinating a multi-agent workflow focused on identifying and resolving technical debt.\n",
    "\n",
    "Agent roles:\n",
    "{roles}\n",
    "\n",
    "Conversation history:\n",
    "{history}\n",
    "\n",
    "Based on the above context, select the most appropriate agent from {participants} to perform the next step in the workflow.\n",
    "\n",
    "Important:\n",
    "- Ensure that the Technical_debt_identifier has initiated the process before others proceed.\n",
    "- Follow the logical sequence: identification → suggestion → refactoring → testing → approval.\n",
    "- Only one agent should be selected at a time.\n",
    "\n",
    "Choose the agent best positioned to advance the current task.\n",
    "\"\"\"\n",
    "\n",
    "# Candidate function to narrow down eligible agents#\n",
    "#def candidate_func(messages: List[BaseChatMessage], agents: List[AssistantAgent]) -> List[AssistantAgent]:\n",
    "def candidate_func(messages: Sequence[BaseAgentEvent | BaseChatMessage]) -> List[str]:\n",
    "    last_msg = messages[-1]\n",
    "    last_sender = messages[-1].source\n",
    "\n",
    "\n",
    "    if last_sender == \"user\":\n",
    "        return [debt_agent.name]\n",
    "    if last_sender == \"Technical_debt_identifier\":\n",
    "        return [suggestion_agent.name]\n",
    "    elif last_sender == \"Technical_debt_refactoring_suggestor\":\n",
    "        return [refactoring_agent.name]\n",
    "    elif last_sender == \"Technical_debt_refactoring_agent\":\n",
    "        return [test_agent.name]\n",
    "    elif last_sender == \"Test_agent\":\n",
    "        print(\"-------------------> last msg\",last_msg)\n",
    "        if \"approved\" in last_msg or \"looks good\" in last_msg or \"yes\" in last_msg:\n",
    "            return []  # Terminate\n",
    "        else:\n",
    "            return [refactoring_agent.name]  # Loop back for improvements\n",
    "    return agents  # Default fallback\n",
    "\n",
    "def candidate_func_adapter(thread) -> List[AssistantAgent]:\n",
    "    print(thread)\n",
    "    return candidate_func(thread.messages, thread.agents)\n",
    "\n",
    "    \n",
    "# Create the group chat\n",
    "team = SelectorGroupChat(\n",
    "    [debt_agent, suggestion_agent, refactoring_agent, test_agent],\n",
    "    model_client=model_client,\n",
    "    #selector=WorkflowSelector(),\n",
    "    termination_condition=termination,\n",
    "    candidate_func=candidate_func,\n",
    ")\n",
    "# Create the group chat\n",
    "#group_chat = SelectorGroupChat(\n",
    "#    agents=[reviewer, fixer, tester],\n",
    "#    selector=select_speaker,  # Default model-based selector\n",
    "#    candidate_func=candidate_func,\n",
    "#    allow_repeat_speaker=False\n",
    "#)\n",
    "task = f\"Analyze the following code and identify technical debt:\\n\\n{code_content}. Then suggest a refactoring strategy and refactor the code.\"\n",
    "await Console(team.run_stream(task=task))\n",
    "\n",
    "#manager = GroupChatManager(groupchat=group_chat)\n",
    "\n",
    "# Entry point\n",
    "#user_proxy = UserProxyAgent(name=\"User\", code_execution_config=False)\n",
    "\n",
    "# Start the chat\n",
    "#user_proxy.initiate_chat(\n",
    "#    manager,\n",
    "#    message=\"Here's a piece of code. Can you help me review and improve it?\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bbecdc-0773-4112-818f-9295b932a958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16953378-402a-4647-914c-1b4af494cc31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
